{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "# general tools\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# RDkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "# Pytorch and Pytorch Geometric\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some Warnings informing about future scipy changes.\n",
    "\n",
    "We will suppress them here as they have no influence on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select processor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('The code uses a GPU...')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('The code uses a CPU...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data\n",
    "\n",
    "Here we use classification data on blood brain barrier (BBB) penetration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_table('B3DB_regression.tsv',sep='\\t')\n",
    "\n",
    "table = tmp.loc[:,('compound_name', 'IUPAC_name', 'SMILES', 'logBB')]\n",
    "table = table.dropna(subset=\"logBB\")\n",
    "table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "task = 'regression'\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(x, permitted_list):\n",
    "    \"\"\"\n",
    "    Maps input elements x which are not in the permitted list to the last element\n",
    "    of the permitted list.\n",
    "    \"\"\"\n",
    "    if x not in permitted_list:\n",
    "        x = permitted_list[-1]\n",
    "    binary_encoding = [int(boolean_value) for boolean_value in list(map(lambda s: x == s, permitted_list))]\n",
    "    return binary_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generating atom features\n",
    "\n",
    "The features include\n",
    "\n",
    "- Atom element\n",
    "- Number of heavy atom neighbors\n",
    "- Formal charge\n",
    "- Hybridization\n",
    "- Is in ring\n",
    "- Is part of aromatic bond\n",
    "- Atomic mass\n",
    "- VdW radius\n",
    "- covalend radius\n",
    "- optional: chirality\n",
    "- optional: number of bonded hydrogens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atom_features(atom, \n",
    "                      use_chirality = True, \n",
    "                      hydrogens_implicit = True):\n",
    "    \"\"\"\n",
    "    Takes an RDKit atom object as input and gives a 1d-numpy array of atom features as output.\n",
    "    \"\"\"\n",
    "    # define list of permitted atoms\n",
    "    \n",
    "    #permitted_list_of_atoms =  ['C','N','O','S','F','Si','P','Cl','Br','Mg','Na','Ca','Fe','As','Al','I', 'B','V','K','Tl','Yb','Sb','Sn','Ag','Pd','Co','Se','Ti','Zn', 'Li','Ge','Cu','Au','Ni','Cd','In','Mn','Zr','Cr','Pt','Hg','Pb','Unknown']\n",
    "    permitted_list_of_atoms =  ['C','N','O','S','F','Si','P','Cl','Br','I', 'B', 'Unknown']\n",
    "    \n",
    "    if hydrogens_implicit == False:\n",
    "        permitted_list_of_atoms = ['H'] + permitted_list_of_atoms\n",
    "    \n",
    "    # compute atom features\n",
    "    \n",
    "    atom_type_enc = one_hot_encoding(str(atom.GetSymbol()), permitted_list_of_atoms)\n",
    "    \n",
    "    n_heavy_neighbors_enc = one_hot_encoding(int(atom.GetDegree()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
    "    \n",
    "    formal_charge_enc = one_hot_encoding(int(atom.GetFormalCharge()), [-3, -2, -1, 0, 1, 2, 3, \"Extreme\"])\n",
    "    \n",
    "    hybridisation_type_enc = one_hot_encoding(str(atom.GetHybridization()), [\"S\", \"SP\", \"SP2\", \"SP3\", \"SP3D\", \"SP3D2\", \"OTHER\"])\n",
    "    \n",
    "    is_in_a_ring_enc = [int(atom.IsInRing())]\n",
    "    \n",
    "    is_aromatic_enc = [int(atom.GetIsAromatic())]\n",
    "    \n",
    "    atomic_mass_scaled = [float((atom.GetMass() - 10.812)/116.092)]\n",
    "    \n",
    "    vdw_radius_scaled = [float((Chem.GetPeriodicTable().GetRvdw(atom.GetAtomicNum()) - 1.5)/0.6)]\n",
    "    \n",
    "    covalent_radius_scaled = [float((Chem.GetPeriodicTable().GetRcovalent(atom.GetAtomicNum()) - 0.64)/0.76)]\n",
    "    atom_feature_vector = atom_type_enc + n_heavy_neighbors_enc + formal_charge_enc + hybridisation_type_enc + is_in_a_ring_enc + is_aromatic_enc + atomic_mass_scaled + vdw_radius_scaled + covalent_radius_scaled\n",
    "                                    \n",
    "    if use_chirality == True:\n",
    "        chirality_type_enc = one_hot_encoding(str(atom.GetChiralTag()), [\"CHI_UNSPECIFIED\", \"CHI_TETRAHEDRAL_CW\", \"CHI_TETRAHEDRAL_CCW\", \"CHI_OTHER\"])\n",
    "        atom_feature_vector += chirality_type_enc\n",
    "    \n",
    "    if hydrogens_implicit == True:\n",
    "        n_hydrogens_enc = one_hot_encoding(int(atom.GetTotalNumHs()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
    "        atom_feature_vector += n_hydrogens_enc\n",
    "    return np.array(atom_feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generating bond features\n",
    "\n",
    "Features include\n",
    "\n",
    "- Bond type\n",
    "- Is conjugated\n",
    "- Is part of ring\n",
    "- Optional: Stereochemistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bond_features(bond, \n",
    "                      use_stereochemistry = True):\n",
    "    \"\"\"\n",
    "    Takes an RDKit bond object as input and gives a 1d-numpy array of bond features as output.\n",
    "    \"\"\"\n",
    "    permitted_list_of_bond_types = [Chem.rdchem.BondType.SINGLE, Chem.rdchem.BondType.DOUBLE, Chem.rdchem.BondType.TRIPLE, Chem.rdchem.BondType.AROMATIC]\n",
    "    bond_type_enc = one_hot_encoding(bond.GetBondType(), permitted_list_of_bond_types)\n",
    "    \n",
    "    bond_is_conj_enc = [int(bond.GetIsConjugated())]\n",
    "    \n",
    "    bond_is_in_ring_enc = [int(bond.IsInRing())]\n",
    "    \n",
    "    bond_feature_vector = bond_type_enc + bond_is_conj_enc + bond_is_in_ring_enc\n",
    "    \n",
    "    if use_stereochemistry == True:\n",
    "        stereo_type_enc = one_hot_encoding(str(bond.GetStereo()), [\"STEREOZ\", \"STEREOE\", \"STEREOANY\", \"STEREONONE\"])\n",
    "        bond_feature_vector += stereo_type_enc\n",
    "    return np.array(bond_feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generating graph structure for molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_data_from_smiles(smiles, y):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    smiles:  SMILES string of molecule\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    G:       torch_geometric.data.Data object which represents labeled molecular graph\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    # convert SMILES to RDKit mol object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    # get feature dimensions\n",
    "    n_nodes = mol.GetNumAtoms()\n",
    "    n_edges = 2*mol.GetNumBonds()\n",
    "    unrelated_smiles = \"O=O\"\n",
    "    unrelated_mol = Chem.MolFromSmiles(unrelated_smiles)\n",
    "    n_node_features = len(get_atom_features(unrelated_mol.GetAtomWithIdx(0)))\n",
    "    n_edge_features = len(get_bond_features(unrelated_mol.GetBondBetweenAtoms(0,1)))\n",
    "    \n",
    "    # construct node feature matrix X of shape (n_nodes, n_node_features)\n",
    "    X = np.zeros((n_nodes, n_node_features))\n",
    "    for atom in mol.GetAtoms():\n",
    "        X[atom.GetIdx(), :] = get_atom_features(atom)\n",
    "    X = torch.tensor(X, dtype = torch.float)\n",
    "        \n",
    "    # construct edge index array E of shape (2, n_edges)\n",
    "    (rows, cols) = np.nonzero(GetAdjacencyMatrix(mol))\n",
    "    torch_rows = torch.from_numpy(rows.astype(np.int64)).to(torch.long)\n",
    "    torch_cols = torch.from_numpy(cols.astype(np.int64)).to(torch.long)\n",
    "    E = torch.stack([torch_rows, torch_cols], dim = 0)\n",
    "        \n",
    "    # construct edge feature array EF of shape (n_edges, n_edge_features)\n",
    "    EF = np.zeros((n_edges, n_edge_features))\n",
    "    for (k, (i,j)) in enumerate(zip(rows, cols)):\n",
    "        EF[k] = get_bond_features(mol.GetBondBetweenAtoms(int(i),int(j))) \n",
    "    EF = torch.tensor(EF, dtype = torch.float)\n",
    "\n",
    "    # construct label tensor\n",
    "    y_tensor = torch.tensor(np.array([y]), dtype = torch.float)\n",
    "\n",
    "    # construct Pytorch Geometric data object and append to data list\n",
    "    G = Data(x = X, edge_index = E, edge_attr = EF, y=y_tensor)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data list of graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create molecular graph objects from list of SMILES x_smiles and add to table\n",
    "data_list = []\n",
    "for i in table.index:\n",
    "    graph_data = create_graph_data_from_smiles(table.loc[i,'SMILES'], table.loc[i, 'logBB'])\n",
    "    print(graph_data)\n",
    "    data_list.append(graph_data)\n",
    "\n",
    "n_node_features = data_list[0]['x'][0].shape[0]\n",
    "print(n_node_features)\n",
    "n_edge_features = data_list[0]['edge_attr'][0].shape[0]\n",
    "print(n_edge_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(data_list[0]['x'][0])\n",
    "print(data_list[0]['edge_index'])\n",
    "print(data_list[0]['edge_attr'])\n",
    "# create dataloader for training\n",
    "#dataloader = DataLoader(dataset = data_list, batch_size = 2**7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test set\n",
    "\n",
    "Here, we use random splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "import random\n",
    "\n",
    "debug_mode = False\n",
    "if debug_mode:\n",
    "    fo1 = open(\"debug1.txt\", \"w\")\n",
    "    for i in data_list:\n",
    "        fo1.write('{}\\n'.format(i['x']))\n",
    "        fo1.write('{}\\n'.format(i['edge_index']))\n",
    "        fo1.write('{}\\n'.format(i['edge_attr']))\n",
    "        fo1.write('{}\\n'.format(i['y']))\n",
    "    fo1.close()\n",
    "\n",
    "# shuffle data\n",
    "random.shuffle(data_list)\n",
    "\n",
    "if debug_mode:\n",
    "    fo1 = open(\"debug2.txt\", \"w\")\n",
    "    for i in data_list:\n",
    "        fo1.write('{}\\n'.format(i['x']))\n",
    "        fo1.write('{}\\n'.format(i['edge_index']))\n",
    "        fo1.write('{}\\n'.format(i['edge_attr']))\n",
    "        fo1.write('{}\\n'.format(i['y']))\n",
    "    fo1.close()\n",
    "\n",
    "num_data = len(data_list)\n",
    "num_train = int(0.6*num_data)\n",
    "num_valid = int(0.2*num_data)\n",
    "num_test = int(num_data - num_train - num_valid)\n",
    "\n",
    "train_data = data_list[:num_train]\n",
    "valid_data = data_list[num_train:num_train+num_valid]\n",
    "test_data = data_list[num_train+num_valid:]\n",
    "\n",
    "\n",
    "print(num_data, len(train_data), len(valid_data), len(test_data))\n",
    "#print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Datasets for pytorch\n",
    "\n",
    "We generate three instances (training, validation and test set) of a class Data that is derived from the pytorch class Dataset.\n",
    "\n",
    "Then, we initiate three dataloaders for the three instances that will be used to provide data to the training, validation and test phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "batch_size = 128\n",
    "\n",
    "# Instantiate training, validation and test data\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(dataset=valid_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for Message pass\n",
    "\n",
    "Message pass is here performed using GCN layers where neighboring node features are first transformed by a weight matrix, normalized by their degree, and finally summed up. Lastly, we apply the bias vector to the aggregated output. This formula can be divided into the following steps:\n",
    "\n",
    "1. Initial embedding of node features\n",
    "\n",
    "2. Add self-loops to the adjacency matrix.\n",
    "\n",
    "3. Linearly transform node feature matrix.\n",
    "\n",
    "4. Compute normalization coefficients.\n",
    "\n",
    "5. Normalize node features in \n",
    "\n",
    "6. Sum up neighboring node features (\"add\" aggregation).\n",
    "\n",
    "7. Apply a final bias vector.\n",
    "\n",
    "8. Readout: Generate graph embedding from node embeddings\n",
    "\n",
    "9. FCNN for generating regression output\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_i^{(k)} = \\sum_{j \\in \\mathcal{N}(i) \\cup \\{ i \\}} \\frac{1}{\\sqrt{\\deg(i)} \\cdot \\sqrt{\\deg(j)}} \\cdot \\left( \\mathbf{W}^{\\top} \\cdot \\mathbf{x}_j^{(k-1)} \\right) + \\mathbf{b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.nn.pool import global_mean_pool, global_add_pool\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Parameter\n",
    "\n",
    "output_size = 128\n",
    "radius = 2\n",
    "\n",
    "\n",
    "class GNN_MPNN(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, radius):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.embedding = Linear(in_channels, out_channels, bias=True)\n",
    "        self.lin = Linear(out_channels, out_channels, bias=False)\n",
    "        self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        self.lin_readout = Linear(out_channels, 1, bias=True)\n",
    "        self.radius = radius\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.embedding.reset_parameters()\n",
    "        self.lin.reset_parameters()\n",
    "        self.lin_readout.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        # Step 1: Initial embedding\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Step 2: Add self-loops to the adjacency matrix.\n",
    "        #edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        for r in range(self.radius):\n",
    "            # Step 3: Linearly transform node feature matrix.\n",
    "            x = self.lin(x)\n",
    "            #x = F.relu(x)\n",
    "\n",
    "            # Step 4: Compute normalization.\n",
    "            row, col = edge_index\n",
    "            deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "            deg_inv_sqrt = deg.pow(-0.5)\n",
    "            deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "            norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "            # Step 5-6: Start propagating messages.\n",
    "            x = self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "            # Step 7: Apply a final bias vector.\n",
    "            x += self.bias\n",
    "\n",
    "        # Step 8: Readout\n",
    "        xr = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Step 9: Regression\n",
    "        out = self.lin_readout(xr)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 5: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for evaluating data using dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute_data(model, loader):\n",
    "    with torch.no_grad():\n",
    "        data_eval = []\n",
    "        for (k, batch) in enumerate(loader):\n",
    "            output = model(batch.x, batch.edge_index, batch.batch)\n",
    "            for i in output[:,0]:\n",
    "                data_eval.append(i)\n",
    "    return data_eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "loss_values = []\n",
    "loss_epoch_train = []\n",
    "loss_epoch_valid = []\n",
    "\n",
    "model = GNN_MPNN(n_node_features, output_size, radius).to(device)\n",
    "# define loss function\n",
    "loss_function = MSELoss()\n",
    "# define optimiser\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "# set model to training mode\n",
    "model.train()\n",
    "\n",
    "# loop over training epochs\n",
    "for epoch in range(num_epochs):\n",
    "    loss_epoch = 0\n",
    "    # loop over minibatches for training\n",
    "    for (k, batch) in enumerate(train_dataloader):\n",
    "        # set past gradient to zero\n",
    "        optimiser.zero_grad()\n",
    "        # compute current value of loss function via forward pass\n",
    "        output = model(batch.x, batch.edge_index, batch.batch)\n",
    "        loss_function_value = loss_function(output[:,0], batch.y)\n",
    "        \n",
    "        # loss value for epoch\n",
    "        loss_epoch += batch.x.shape[0]*loss_function_value.item()\n",
    "\n",
    "        # compute current gradient via backward pass\n",
    "        loss_function_value.backward()\n",
    "        # update model weights using gradient and optimisation method\n",
    "        optimiser.step()\n",
    "\n",
    "    \n",
    "    # save loss for each epoch    \n",
    "    loss_epoch_train.append([epoch, loss_epoch/len(train_data)])\n",
    "    # validation loss\n",
    "    with torch.no_grad():\n",
    "        loss_epoch_v = 0\n",
    "        for (k, batch) in enumerate(valid_dataloader):\n",
    "            output = model(batch.x, batch.edge_index, batch.batch)\n",
    "            loss_function_value = loss_function(output[:,0], batch.y)\n",
    "            loss_epoch_v += batch.x.shape[0]*loss_function_value.item()\n",
    "        loss_epoch_valid.append([epoch, loss_epoch_v])\n",
    "    \n",
    "    print(\"% 5d % .3f % .3f\" % (epoch, loss_epoch/len(train_data), loss_epoch_v/len(valid_data)))\n",
    "\n",
    "torch.save(model, \"model_saved.pt\")\n",
    "\n",
    "print(\"Training Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot training loss as function of number of batches (here: One epoch = 10 batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "#plt.plot(step, np.array(loss_values))\n",
    "loss_epoch_train_np = np.asanyarray(loss_epoch_train)\n",
    "plt.plot(loss_epoch_train_np[:,0], loss_epoch_train_np[:,1], \"-\", c=\"r\")\n",
    "plt.title(\"Step-wise Loss\")\n",
    "plt.xlabel(\"Batches\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between experimental and predicted logBB for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model_saved.pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_train = evalute_data(model, train_dataloader)\n",
    "    ground_truth = [i.y[0] for i in train_data]\n",
    "#print(pred_train)\n",
    "#print(ground_truth)\n",
    "\n",
    "\n",
    "# Mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(ground_truth, pred_train))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(ground_truth, pred_train))\n",
    "\n",
    "# Plot outputs\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(ground_truth, pred_train, color=\"black\", s=10)\n",
    "plt.plot([-3.0, 2.0], [-3.0, 2.0], color=\"black\", linewidth=3)\n",
    "\n",
    "plt.xlabel(\"ground truth\")\n",
    "plt.ylabel(\"predicted\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('gnn_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27108f57cd1ba65b5f2ae8c94e82c814223794f9f91eed5364d5a4e57eed0244"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
